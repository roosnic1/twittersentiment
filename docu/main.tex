\documentclass[12pt, oneside]{report}   	% use "amsart" instead of "article" for AMSLaTeX format
\usepackage{geometry}                		% See geometry.pdf to learn the layout options. There are lots.
\geometry{a4paper}                   		% ... or a4paper or a5paper or ... 
%\geometry{landscape}                		% Activate for for rotated page geometry
%\usepackage[parfill]{parskip}    		% Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}				% Use pdf, png, jpg, or eps§ with pdflatex; use eps in DVI mode
\usepackage{float}					% TeX will automatically convert eps --> pdf in pdflatex

\usepackage{amssymb}
\usepackage{amsmath}
\usepackage[utf8]{inputenc}
\usepackage[german]{babel}
\usepackage[T1]{fontenc} % ermöglicht die Silbentrennung von Wörtern mit Umlauten
\usepackage[bookmarksnumbered, bookmarksopen=true]{hyperref}  % PDF wird mit Lesezeichen (verlinktes Inhaltsverzeichnis) versehen 

\usepackage{listings} 
\usepackage{fancyhdr}
\pagestyle{fancy}

\fancypagestyle{plain}{}


\fancyhf{}
\fancyfoot{}

%\interfootnotelinepenalty=10000

\title{Twitter Sentiment Analyse}
\author{Seminararbeit für Seminar Paralleles Rechnen\\
	Jérémie Blaser, Nicolas Roos\\
	ZHAW (Zürcher Hochschule für Angewandte Wissenschaften),\\
	Zürich,\\
	Switzerland,\\
	\texttt{blaseje1@students.zhaw.ch},
	\texttt{roosnic1@students.zhaw.ch}}
\date{\today}							% Activate to display a given date or no date


\fancyhead[OEC] {Seminararbeit: Twitter Sentiment Analyse}
\fancyfoot[C] {Seite \thepage}
\fancyfoot[L] {Jérémie Blaser, Nicolas Roos}
\fancyfoot[R] {\today}


\begin{document}
\lstset{language=Python} 
\newcommand{\qem}[1]{\emph{"<#1">}} % quotated emphasize

\maketitle


%\paragraph{Ansprechpartner an der ZHAW} ~\\
%\begin{itemize}
%\item Studiengangleiter: Olaf Stern, Tel: +41 58 934 82 51; olaf.stern@zhaw.ch
%\end{itemize}


\tableofcontents

\chapter{Einleitung}
\section{Motivation}
Mit einer Sentiment Analyse über einen gewissen Zeitraum lässt sich zeigen was die Twitter Community von einem Brand, einer Firma, Personen usw. haltet. Diese Daten könnten Grafisch dargestellt werden und mit dem Aktienkurs der Firma oder signifikanten Ereignissen zu einem gewissen Zeitpunkt verglichen werden. 
\section{Idee}
Mit Suchwörtern wird nach allen Tweets gesucht welche zu einem bestimmten Thema/Firma/Hashtag gehören. Diese Tweets werden mit einer Sentiment Analyse Positiv oder Negativ eingestuft. Diese Einstufung wird in einem Zeit/Polarität Graph dargestellt. \\
Für diese Idee wird eine grosse Menge von Tweets über einen längeren Zeitraum (minimum 2 Monate) benötigt. Momentan ist noch nicht klar ob diese Menge vorhanden ist. Alternativ kann man auch die aktuellen Tweets nach Brand/Firma/Person filtern und über diese Tweets eine Sentiment Analyse laufen lassen.
\section{Meilensteine}
\begin{itemize}
\item Twitter-API anbinden/implementieren
\item Historische Sammlung von Tweets besorgen
\item Evaluation von MapReduce und MPI für unser Problem
\item Paralleles filtern von Tweets nach Keyword/Hashtag implementieren
\item Sentiment Analysis mit NLTK Classifier implementieren (Naive Bayes und MaxEnt)
\item Classifier Trainieren
\item Performanceanalyse erstellen
\item Vergleich Naive Bayes mit MaxEnt
\item GUI programmieren mit Plot des Stimmungsverlaufs
\item Dokumentation schreiben (Seminararbeit)
\end{itemize}


\chapter{Anforderungen}

\section{Twitter Korpus}
Twitter stellt für Entwickler eine moderne API zur Verfügung. Die aktuell version dieser API, Version 1.1, erlaubt dem Benutzer nach Tweets zu suchen oder die Timeline eines Benutzers auszugeben. Die Menge von Tweets die bei solch einer Suche zurückgegeben wird, ist jedoch stark begrenzt. Pro Suche können ca. 15 Seiten mit maximal 100 Tweets gefunden werden\footnote{\url{https://dev.twitter.com/docs/api/1/get/search}}. Bei durchschnittlich 5700 Tweets pro Sekunde\footnote{\url{https://blog.twitter.com/2013/new-tweets-per-second-record-and-how}} ist diese eine sehr geringe Menge. Dieser durchschnitt bezieht sich auf das Jahr 2013 und wird im Jahr 2014 sicherlich steigen.
Dadurch ist die Beschaffung von einer grossen Menge Tweets über diese API nicht möglich.

Als alternative gibt es die komerzielle API von DataSift\footnote{\url{http://dev.datasift.com/docs}}, welche ihre Twitter-Daten vermarktet.

\section{Paralleles Rechnen}
Für die parallele Ausführung wird ein Python Framework benutzt. Für die Sentiment Analyse und das Filtern der Tweets wird kein Cluster verwendet sondern mehrere Worker Prozesse welche auf dem Rechner parallel ausgeführt werden. Ein Grund dafür ist dass die Klassifikationen Algorithmen trainiert werden müssen um richtig zu funktionieren. Diese Trainingsdaten über das Netzwerk auszutauschen, würden in unserem Fall zu einer Verlangsamung führen.
Zur Auswahl standen 2 Python Frameworks. Zum einen das Disco Framework mit dem Map Reduce verfahren. Zum andern das  MPI for Python Framework mit dem Message Passing Interface Verfahren.

\subsection{Evaluation MapReduce vs. MPI}
\subsubsection{Disco - MapReduce}
Disco ist ein leichtes, Open-Source Framework dass das Map Reduce Programmiermodell, welches ursprünglich von Google entwickelt wurde\footnote{\cite{dean}}, anbietet. Für die Installation wird eine Linux/Unix Distribution oder ein Mac OS X System, einen SSH Daemon und Client, Erlang/OTP R14A oder neuer und Python 2.6.6 oder neuer benötigt. Für die Webdarstellung wird entweder Lighttpd 1.4.17 oder neuer oder Varnish 2.1.3 oder neuer benötigt. Disco kann auf dem Mac OS X mit Homebrew\footnote{Packet Manager für Mac OS X} installiert werden. Alternativ kann man auch den Source Code herunterladen und Disco selbständig kompilieren. Nach der installation braucht es noch einige kleinere Konfiguration bis Disco funktionsfähig ist. Danach kann mit Eingabedateien (Textdateien, CSV Dateien) und 2 Funktionen, Map und Reduce, das Framework erfolgreich benutz werden.
\subsubsection{MPI for Python - Message Passing Interface}
Das Message Passing Interface (MPI) ist ein Standard, welcher den Nachrichtenaustausch bei parallelen Berechnungen auf verteilten Computersystem beschreibt. Das MPI for Python Packte wurde auf den MPI-1/MPI2 Spezifikationen aufgebaut und bietet eine Objekt orientierte Schnittstelle an. Für die Installation von MPI for Python wird eine funktionierende MPI Distribution benötigt und Python 2.3 oder neuer. Die Installation ist relative einfach mit PIP\footnote{Installationsprogramm für Python-Pakete} auszuführen. Im Python Script wird die MPI Bibliothek importiert und die Scrips werden mit
\begin{lstlisting}
$ mpirun -n 5 python demo/helloworld.py
\end{lstlisting}
von der Konsole gestartet.

\subsubsection{Fazit}
Wir haben uns für das Disco Framework entschieden wegen der sehr einfachen Handhabung.
Bei der Implementation der parallelen Sentiment Analyse haben wir jedoch bemerkt, dass das Disco Framework für jeden Map-Aufruf alle Parameter zuerst deserialisiert. 
Da ein trainierter Klassifizierer gut 100MB Speicher belegt und es keine andere Möglichkeit gibt, ausser ihn als Parameter zu übergeben, hat das deserialisieren zu einem unakzeptablen Overhead geführt. 
Daher haben wir für die parallele Ausführung der Sentiment Analyse das MPI Framework verwendet.





\chapter{Umsetzung}

\section{Sentiment Analyse}
Die Sentiment Analyse ist ein Verfahren des \emph{Natural Language Processing}, einem interdisziplinären Forschungsgebiet aus Informatik und Linguistik.
Es geht im wesentlichen darum, die in einem Text vorherrschende Stimmung automatisiert zu bestimmen. 
Der zu untersuchende Text kann, wie in unserem Fall mit Tweets, aus nur einzelnen wenigen Sätzen bestehen, welche einer der beiden Klassen mit eher "<positiver"> oder "<negativer"> Stimmung zugeteilt werden.
Dafür verwendet man einen geeigneten Klassifikator, welchen  mit einer Trainingsmenge trainiert wird, um anschliessend die Klassifikation durchzuführen. 

Wir verwenden für diese Arbeit einen Naive-Bayes-Klassifikator sowie einen Maximum-Entropy-Klassifikator, zwei bekannte Klassifikationsalgorithmen des \emph{Machine Learning}, und vergleichen deren Leistung.


\subsection{Trainingsmenge}

Auf der Suche nach einer vorklassifizierten Trainingsmenge für unsere Sentiment Analyse, wurden wir fündig auf \url{http://www.sentiment140.com}. 
Die Entwickler von sentiment140 haben ein automatisiertes Klassifikationsverfahren verwendet, welches sie \qem{distant supervised learning} nennen. 
Sie haben dafür die  Emoticons (Smileys, wie z.B. \verb|:-)|, \verb|:(| und \verb|:-D|) in den Tweets für eine Klassifikation herangezogen. 
Dieses Verfahren ist natürlich nicht gleich akkurat wie eine menschlich vorgenommene Klassifikation, dafür lässt sich damit ein grosser klassifizierter Korpus erstellen.

Der Korpus beinhaltet 1.6 Millionen klassifiezierte Tweets in einer CSV Datei und hat folgende 6 Datenfelder:
\begin{enumerate}
\item Polarität (0 = negativ, 2 = neutral, 4 = positiv)
\item ID des Tweets
\item Datum
\item Die Suchabfrage mit der der Tweet gefunden wurde
\item Benutzer welcher der Tweet geschrieben hat
\item Text des Tweets
\end{enumerate}


\subsection{Tweet Preprocessing}
Die Tweets im Trainings-Set, wie auch die Abfrageparameter für den Klassifikator müssen ein einheitliches Format haben.
Wir verwenden dafür das bekannte \qem{Bag of words model}\footnote{\cite{ai}:866}, welches nur \emph{feature/value} Paare beinhaltet.
Die einzelnen Wörter eines Tweets bilden dabei die Features, welche alle die Value \verb|True| haben.
Die Information wie oft ein Wort in einem Tweet vorkommt und in welcher Reihenfolge, geht in diesem Modell verloren. Dafür kann man direkt mit mathematischen Funktionen darauf operieren, wie wir in Kapitel 3.1.3 sehen werden.

\subsubsection{Parsing}
Um die einzelnen Wörter aus einem Tweet herauszubekommen, um sie in den Bag of words füllen zu können, muss man diese zuerst herausparsen. 
Wir verwenden dafür die Klasse \verb|nltk.tokenize.wordpunct_tokenize| des NLTK-Frameworks\footnote{Natural Language Toolkit, \url{http://www.nltk.org}}.

\subsubsection{Feature Reduction}
Viele Wörter, vor allem sogenannte Stopwörter, aber auch Satzzeichen und andere Wortfragmente, können keine Information über die Stimmung in einem Tweet liefern. 
Diese Features werden deshalb vor dem Training entfernt, um das Modell des Klassifizierers nicht zu verzerren.

Insbesondere bei Tweets gibt es eine ganze Menge von Features welche keinen Beitrag zur Sentiment Analyse liefern, und wir deshalb entfernen. 
Es sind dies u.a. folgende Bestandteile eines Tweets:

\begin{itemize}
\item @User
\item \#Hashtags
\item URLs (also Links, beginnend mit http://...)
\item Retweets (beginnen mit RT)
\item HTML-Entities (z.B. \& codiert als \&amp;)
\end{itemize}


Die vollständige Liste der vorgenommenen Entfernungen ist im Quelltext der beiden Methoden \verb|preprocessTweet()| und \verb|filtered_bag_of_words()| in der Datei \verb|classifier_utils.py| ersichtlich. 



\subsection{Klassifikationsalgorithmen}
\subsubsection{Naive-Bayes}

Der Naive-Bayes-Klassifikator macht sich die Wahrschentlichkeitsverteilung der Klassen und Features im Trainings-Set, sowie die Anwendung des Bayes-Theorem (Satz von Bayes) zunutze.

Die Wahrscheinlichkeit dass ein Tweet, bestehend aus den Wörtern (Features) $F_1,\dots,F_n$, zu einer Klasse $C$ gehört, lässt sich als bedingte Wahrscheinlichkeit formulieren:
$$ P(C \mid F_1,\dots,F_n)$$

Für grosse $n$ wird diese Berechnung jedoch schwierig. Der Satz von Bayes erlaubt uns aber dieses Problem anders zu formulieren:
$$
P(C \mid F_1,\dots,F_n) = \frac{P(C) \ P(F_1,\dots,F_n\mid C )}{P(F_1,\dots,F_n)}
$$

Treffen wir weiter die \emph{naive} Annahme, dass gegeben einer Klasse $C$ das Auftreten der Features untereinander unabhängig ist,
d.h. es gilt $P(F_i,F_j) = P(F_i)P(F_j)$, können wir die Regel der bedingten Unabhängigkeit\footnote{\cite{alp}:389 }

$$ P(X,Y \mid Z) = P(X \mid Z) \ P(Y \mid Z) $$
anwenden und die Berechnung weiter vereinfachen zu
$$
P(C \mid F_1,\dots,F_n) = \frac{1}{W} \, P(C) \prod_{i=1}^n P(F_i\mid C)\ \ \ \mathrm{mit} \ \ W = P(F_1,\dots,F_n).
$$

Nun können wir unabhängig von der Grösse unseres Trainings-Set, durch einfaches abzählen der Wörter und Klassen, die gesuchten Wahrscheinlichkeiten berechnen.
Da $W$ konstant ist für einen gegebenen Input, können wir diesen Bruch weglassen und erhalten unseren Naive-Bayes-Klassifikator:
$$ \mathrm{classify}(f_1,\dots,f_n) = \underset{c \, \in \, \{pos,neg\} }{\operatorname{arg\,max}} \ P(c) \displaystyle\prod_{i=1}^n P(f_i\mid c) $$

Die naive Annahme, welche namensgebend ist für das Verfahren, entspricht natürlich nicht der Realität. 
Trotzdem lassen sich in der Praxis gute Resultate erzielen mit diesem Verfahren.\footnote{\cite{ai}:499}
\\

In unserer Implementation verwenden wir die Klasse\\
 \verb|nltk.classify.NaiveBayesClassifier| des NLTK-Frameworks.
 
%O(n)


\subsubsection{MaxEnt}

Der Maximum-Entropy-Klassifikator, kurz \emph{MaxEnt}, ist auch ein probabilistischer Klassifikator. Im unterschied zum Naive-Bayes-Klassifikator, kann er jedoch auch mit abhängigen Features umgehen und diese gut modellieren.
In der Fachliteratur findet man fast nichts zu \emph{MaxEnt}. Dies liegt sehr wahrscheinlich daran, dass es mehrere Namen für das selbe Verfahren gibt. 
Auf Wikipedia\cite{mlr} werden diese Verfahren unter \qem{Multinomial logistic regression} zusammengefasst. Dort gibt es auch eine Auflistung der verschiedenen Namen.

In der binären Variante, d.h. wenn man nur zwei Klassen betrachtet, ist das Verfahren das selbe wie die logistische Regression. Wir verwenden daher in unserer Implementation die Klasse
\verb|nltk.classify.scikitlearn.SklearnClassifier| zusammen mit
\verb|sklearn.linear_model.LogisticRegression| des scikit-learn Frameworks\footnote{\url{http://scikit-learn.org}}.



\section{Filtern mit MapReduce}
Das Filtern der Tweets wird mit dem Disco MapReduce Framework parallel ausgeführt. Die CSVJob Klasse erweitert die Job Klasse von dem Disco Framework. Das Keyword nach welchem gefiltert werden soll, kann nach der Initialisierung gesetzt werden. Beim starten des Jobs werden die Eingabedaten (CSV Dateien mit Tweets) übergeben. Für jede einzelne Datei wird ein eigener Worker gestartet und parallel ausgeführt. Das heisst die Eingabe Daten müssen bereits in gleichmässig grossen CSV Dateien verfügbar sein. Pro Worker wird nun eine \emph{map} Funktion gestartet. Die Funktion gibt nur die Tweets zurück an die \emph{reduce} Funktion welche das Keyword beinhalten. Die \emph{reduce} Funktion sammelt die Tweets aller Worker zusammen und gibt sie, wenn alle Worker beendet sind, zurück. Die zurück gegeben Daten befinden sich in einem Python Generator und werden direkt in eine CSV Dateien gespeichert und der Sentiment Analyse übergeben.

\section{Parallele Sentiment Analyse}
Die Sentiment Analyse wird mit dem MPI for Python Framework parallel ausgeführt. Die Funktion erwartet eine CSV Datei mit Tweets. Die gesamte Datei wird in ein Array geladen und dann gleichmässig aufgeteilt auf die Anzahl Worker mit denen der Prozess gestartet wurde. 
Der Classifier wird auf jedem Worker einmal instanziert und mit den trainierten Modell-Daten geladen. 
Die aufgeteilten Arrays werden den Worker übergeben, welche für jeden Tweet einmal die Funktion \emph{classify\_tweet} aufgerufen. Wenn die Analyse positiv verläuft kriegt der Tweet eine +1 ansonsten eine -1. \newline{} 
%
Für jeden Tweet wird das Datum in ein \emph{datetime} Objekt umgewandelt und auf den Tag, Monat und das Jahr des Tweets reduziert. Alle Sentiment Werte werden für einen Tag zusammen gezählt und geben so einen Stimmungsverlauf.

\section{GUI}
%Wieso weg gelassen
Das GUI\footnote{Graphical User Interface} haben wir aufgrund der knappen Zeitverhältnisse weg gelassen. Die Funktionen jedoch wurden alle so entwickelt, dass sie ohne weiteres aus einem GUI aufgerufen werden können.


\chapter{Resultat}

\section{Naive Bayes vs. MaxEnt}

Für den Vergleich der beiden Klassifikationsalgorithmen verwenden wir unterschiedlich grosse Trainingssets und werten die \emph{Accuracy} ($= \frac{\#richtige}{\#total}$ ) aus. 
Als Testset dient das ebenfalls dem Korpus von sentiment140.com beiliegende, welches 499 von Hand klassifizierte Tweets umfasst.

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=0.75\textwidth]{bilder/cmp_nb_vs_me_S10_M300-16M.pdf}
\caption{Accuracy}
\label{img:acc}
\end{center}
\end{figure}

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=0.75\textwidth]{bilder/cmp_nb_vs_me_S200_M6000.pdf}
\caption{Accuracy, Step 200}
\label{img:acc2}
\end{center}
\end{figure}

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=0.75\textwidth]{bilder/cmp_nb_vs_me_S1000_M100000.pdf}
\caption{Accuracy, Step 1000}
\label{img:acc3}
\end{center}
\end{figure}


\section{Performancevergleich}
Für die Performancetests wurde ein MacBook Pro, Late 2013 mit folgenden Komponenten verwendet:
\begin{description}
\item[ Prozessor] 2.6 GHz Intel Core i7 (4 physisch, 8 virtuelle)
\item[ Arbeitsspeicher] 16 GB 1600 MHz DDR3
\item[ Betriebsystem] OS X 10.9.3
\item[ Python] Version 2.7.7
\item[ Disco ] Version 0.5-56-g136b1ac
\item[ MPI ] Version 3.1
\end{description}

\subsection{Sentiment Analyse}
Für den Performancevergleich wurde der Naive Bayes  Klassifikatior verwendet. Es ist sehr schnell ersichtlich, dass die parallele Ausführung der Sentiment Funktion bedeutend Schneller ist. In Abbildung 4.4 sieht man 4 parallele Jobs (4,6,7 und 8 Workers) und einen seriellen Job. Der schnellste parallele Job braucht für 1'000'000 Tweets 38.9 Sekunden und der serielle Job benötigt für dieselbe Menge 110.2 Sekunden. 

\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.7\textwidth]{bilder/time_senitment_par-ser.pdf}
\caption{Sentiment Analyse (par vs ser)}
\label{img:performancesentiment}
\end{center}
\end{figure}

%Fitler: 10 workers, MPI: 4 workers
%[(0.708772, 1000), (1.070244, 10000), (4.545117, 100000), (40.366181, 1000000)]
%Fitler: 10 workers, MPI: 6 workers
%[(0.95488, 1000), (1.224783, 10000), (4.383731, 100000), (38.915281, 1000000)]
%Fitler: 10 workers, MPI: 7 workers
%[(1.024954, 1000), (1.296836, 10000), (4.558475, 100000), (40.077041, 1000000)]
%Filter: 20 workers, MPI: 8 workers
%[(1.124848, 1000), (1.523185, 10000), (4.824918, 100000), (41.11099, 1000000)]
%Filter: 1 worker, MPI: 1 worker
%[(0.673428, 1000), (1.669188, 10000), (11.060885, 100000), (110.175096, 1000000)]

Das ändern der Anzahl Worker hat keinen merkbaren Einfluss auf die Ausführungsgeschwindigkeit der Sentiment Analyse. In der Abbildung 4.5 sieht man dass alle 4 parallele Jobs etwa gleich lange brauchen.

\begin{table}[h]
    \begin{tabular}{|l|l|l|l|l|}
    \hline
    Workers/ Tweets         & 1'000    & 10'000   & 100'000  & 1'000'000 \\ \hline
    4 Workers & 0.730369 & 1.027004 & 4.103374 & 38.110437 \\ \hline
    6 Workers & 0.963817 & 1.177442 & 4.331552 & 38.666975 \\ \hline
    7 Workers & 1.021573 & 1.316651 & 4.289592 & 41.529118 \\ \hline
    8 Workers & 1.112133 & 1.406023 & 4.5955   & 40.263055 \\ \hline
    \end{tabular}
\end{table}

Es war anzunehmen dass mit 6 Workern eine schneller Ausführung erreicht werden kann, weil die 2 restlichen Prozessorkerne den overhead kompensieren könnten. Dies war aber nicht der Fall.

\begin{figure}[h]
\begin{center}
\includegraphics[width=0.75\textwidth]{bilder/time_senitment_par.pdf}
\caption{Sentiment Analyse}
\label{img:performancesentiment}
\end{center}
\end{figure}

%Fitler: 10 workers, MPI: 4 workers
%[(0.730369, 1000), (1.027004, 10000), (4.103374, 100000), (38.110437, 1000000)]
%Fitler: 10 workers, MPI: 6 workers
%[(0.963817, 1000), (1.177442, 10000), (4.331552, 100000), (38.666975, 1000000)]
%Fitler: 10 workers, MPI: 7 workers
%[(1.021573, 1000), (1.316651, 10000), (4.289592, 100000), (41.529118, 1000000)]
%Filter: 20 workers, MPI: 8 workers
%[(1.112133, 1000), (1.406023, 10000), (4.5955, 100000), (40.263055, 1000000)]

\subsection{Tweets Filtern}
Abbildung 4.6  zeigt dass die parallele Ausführung der Filter Funktion signifikant schneller ist als die serielle Ausführung. Betrachtet man Abbildung 4.6 und 4.7 sieht man dass die Wahl des Keywords keinen Einfluss auf die Geschwindigkeit der Funktion haben.
\begin{figure}[h]
\begin{center}
\includegraphics[width=0.7\textwidth]{bilder/time_filter_apple.pdf}
\caption{Performance keyword 'apple'}
\label{img:performancefilter1}
\end{center}
\end{figure}

\begin{figure}[h]
\begin{center}
\includegraphics[width=0.7\textwidth]{bilder/time_filter_google.pdf}
\caption{Performance keyword 'obama'}
\label{img:performancefilter3}
\end{center}
\end{figure}


\clearpage

\section{Plot Stimmungsverlauf}

\begin{figure}[h]
\begin{center}
\includegraphics[width=0.9\textwidth]{bilder/moodPlotApple.pdf}
\caption{Stimmungsverlauf 'Apple'}
\label{img:moodplot1}
\end{center}
\end{figure}

\begin{figure}[h]
\begin{center}
\includegraphics[width=0.9\textwidth]{bilder/moodPlotGoogle.pdf}
\caption{Stimmungsverlauf 'Google'}
\label{img:moodplot2}
\end{center}
\end{figure}


\chapter{Fazit}
Die Parallele Ausführung der Sentiment Analyse und des Filterns ist ab einer grossen Anzahl Tweets bedeutend Schneller. Bei unseren Tests war die parallele Ausführung beim Filtern immer um den Faktor 2 schneller als die serielle Ausführung. Es ist zu erwarten dass dieser Faktor bei einer grösseren Menge an Tweets bestehen bleibt. Interessant ist auch dass der Overhead bei der parallelen Ausführung bei 100'000 und weniger Tweets ca. genau soviel Zeit einnimmt wie die serielle Ausführung.

Bei der Sentiment Analyse ist schon bei weniger Tweets erkennbar dass die parallele Ausführung schneller ist. Bereits bei 100'00 Tweets dauert die serielle Ausführung bereits 2 mal so lange. Bei 1'000'000 Tweets braucht es schon fast 3 mal so lange. Es ist zu erwarten dass dieser Faktoren bei mehr Tweets zu nimmt.\\


Der Naive-Bayes-Klassifikator ist dem MaxEnt-Klassifikator bei unserem Vergleich klar unterlegen. 
Besonders ab einer Trainingsset-Grösse von 10000 Tweets wird ein grosser Unterschied sichtbar.
Dies legt die Vermutung nahe, dass die Fähigkeit von MaxEnt mit abhängigen Features umzugehen den Unterschied ausmacht.

Die Accuracy beider Verfahren liesse sich durch ein anderes Trainingsset wahrscheinlich noch weiter erhöhen.


% D. Literaturverzeichnis
%***************************************************************************************************
\clearpage
\phantomsection
\addcontentsline{toc}{chapter}{Literaturverzeichnis}


\linespread{1.2}\selectfont
\begin{thebibliography}{99}

\bibitem{alp} \textsc{Alpaydin}, Ethem: \emph{Introduction to Machine Learning (2nd ed.)}. The MIT Press, 2010.

\bibitem{dean} \textsc{Dean}, Jeffrey und \textsc{Ghemawat}, Sanjay: \emph{ MapReduce: Simplified Data Processing on Large Clusters}. In: Sixth Symposium on Operating System Design and Implementation, San Francisco 2004.

\bibitem{ai} \textsc{Russell}, Stuart J. und \textsc{Norvig}, Peter: \emph{Artificial Intelligence: A Modern Approach (3rd ed.)}. Pearson Education, 2003.

\bibitem{mlr} Wikipedia: \emph{Multinomial logistic regression}. \url{http://en.wikipedia.org/wiki/Multinomial_logistic_regression} (Stand 14.6.2014) 


\end{thebibliography}

\end{document}